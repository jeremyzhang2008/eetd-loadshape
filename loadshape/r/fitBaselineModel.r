#
#
#####################
#####################

getTime = function(timeInfo,verbose=1,format=NULL) {
	# given a vector of timestamps using one of the following timestamp formats, return
	# a vector of POSIXlt times:
	# 1. Year-month-day Hours:Minutes
	# 1. Year-month-day Hours:Minutes:Seconds
	# 2. Seconds since 1970-01-01 00:00:00
	# 3. Milliseconds since 1970-01-01 00:00:00 (as generated by sMAP for example)
	# 
	if (verbose > 1) { print("starting getTime()")}

	if (class(timeInfo)[1] %in% c("POSIXct","POSIXlt")) { return(timeInfo) }
	
	if (verbose > 3) { print(timeInfo[1]) }
	if (!is.null(format)) {
		time = strptime(timeInfo,format=format)
		return(time)
	}	
	
	if(grepl(":",timeInfo[1])[1]) {
		nColons = sapply(regmatches(timeInfo[1], gregexpr(":", timeInfo[1])), length)
		if (nColons == 1) {
			format = "%Y-%m-%d %H:%M"
		} else {
			format = "%Y-%m-%d %H:%M:%S"
		}
		time = strptime(timeInfo,format=format)
		
	} else {
		if (!is.numeric(timeInfo[1])) {
			stop("Time is not in a recognized format")
		}
		if (timeInfo[1] > 3e9) {
			# If time is in seconds, then this would represent sometime after 2066 
			# so assume time is in milliseconds	
			timeNum = timeInfo/1000
		} else {
			timeNum = timeInfo
		}		
		time = as.POSIXlt(timeNum,origin="1970-01-01")
	}
	return(time)	
}



#
combineWeatherData = function(directory=NULL,intervalMinutes=15) {
	# This function was written to combine weather data (specifically
	# outdoor air temperature) from several datafiles, and generate a single file
	# from them. This is motivated by the need to handle Weather Underground files:
	# we typically get data from several weather stations within a zip code, and need
	# to generate a single temperature file.
	if(is.null(directory)) {
		command = "ls *.csv"
	} else {
		command = paste("ls ",directory,"/*.csv",sep="")
	}
	fileList = system(command, intern=T)
	nFiles = length(fileList)
	
	iFile=0
	start=rep(NA,length(fileList))
	end=rep(NA,length(fileList))
	
	datList = NULL
	for (file in fileList) {
		iFile = iFile+1
		dat = read.table(file,header=F,sep=",",as.is=T)
		start[iFile] = dat[1,1]
		end[iFile] = tail(dat[,1],1)
		datList[[iFile]] = dat
	}
	
	outStart = min(as.numeric(getTime(start,format="%m/%d/%Y %H:%M")))
	# start at the top of the first hour for which we have data.
	
	outEnd = max(as.numeric(getTime(end,format="%m/%d/%Y %H:%M")))
	outVec = seq(from=outStart,to=outEnd,by=intervalMinutes*60)
	
	val = matrix(NA,nrow=length(outVec),ncol=nFiles)
	# interpolate the data from each datafile to get a prediction at each output 
	# timestamp
	for (iFile in 1:nFiles) {
		t = as.numeric(getTime(datList[[iFile]][,1],format="%m/%d/%Y %H:%M"))
		val[,iFile] = approx(t,datList[[iFile]][,2],outVec,method="linear")$y
	}
	
	# At each timestamp, take the median of the values from the different datafiles.
	# Taking the median makes this robust against one or more stations returning
	# bad values, which happens fairly frequently.
	outVal = apply(val,1,median,na.rm=T)
	
	
	outTime = getTime(outVec)
	outFrame = data.frame(outTime,outVal)
	Out=NULL
	Out$interpolatedData = val
	Out$results = outFrame
	Out$time = outTime
	return(Out)
	

#
putTimeSeriesOnNiceIntervals = function(timeVec,yVec,outStart=NULL,outEnd=NULL,
	intervalMinutes=60) {
	# Takes an input time series recorded at arbitrary time intervals, outputs 
	# an interpolated time series of mean values at regular intervals.
	# Output starts at the top of the hour of the first data point (or at an optionally specified
	# starting location), at specified intervals. 
	#
	# We need to handle the case when we have data at either higher or lower frequency
	# than desired for the output. First deal with the higher-frequency case (take the
	# mean of all of the data in the interval), then handle the lower-frequency case.
	#
	
	
	timeIn = getTime(timeVec)
	numTimeIn = as.numeric(timeIn)
	
	if (is.null(outStart)) { 
		# if no time is specified for the start of the output series, start at the top of
		# the hour for the first hour that has data.
		outStart = strptime(timeIn[1],format="%Y-%m-%d %H") 
	}
	numTimeStart = as.numeric(getTime(outStart))
		
	if (is.null(outEnd)) {
		numTimeEnd = as.numeric(tail(timeIn,1))
	} else {
		numTimeEnd = as.numeric(getTime(outEnd))
	}
	outTimeNum = seq(from=numTimeStart,to=numTimeEnd,by=intervalMinutes*60)
	
	intervalsSinceStart = (numTimeIn-numTimeStart)/(intervalMinutes*60)
	nIntervalsSinceStart = floor(intervalsSinceStart)
	maxIntervals = floor((numTimeEnd-numTimeStart)/(intervalMinutes*60))
	
	aggregatedDat = aggregate(yVec,by=list(nIntervalsSinceStart),
		mean,na.rm=T)
	
	aggInterval = aggregatedDat[[1]]
	okNotTooEarly = aggInterval >= 0
	okNotTooLate = aggInterval < maxIntervals
		
	outTime = getTime(outTimeNum)
	nPoints = length(outTime)
	
	yOut = rep(NA,nPoints)
	ok = okNotTooEarly & okNotTooLate
	yOut[aggInterval[ok]+1] = aggregatedDat[[2]][ok]	
	yOut = yOut[1:nPoints]
	
	# Now interpolate to fill in any NA values
	okNotNA = !is.na(yOut)
	yOut = approx(outTimeNum[okNotNA],yOut[okNotNA],outTimeNum,rule=1)$y
	
	
	Out = NULL
	Out$time = outTime
	Out$y = yOut
	return(Out)
}
#

#
#
imputeTimeSeries = function(timeVec,yVec,outStart=NULL,outEnd=NULL,
	xTime=NULL,xVec=NULL,intervalMinutes=60) {
	# Fill missing data into a time series
	# We also keep track of which points were generated by imputation (as opposed to
	# by interpolation).
	#
	# A time series (xTime,xVec) that predicts yVec may be provided. If it is, it will
	# be used as an additional predictive variable (in addition to time-of-week),
	# assuming a piecewise-linear relationship between x and y.  
	
	niceSeries = putTimeSeriesOnNiceIntervals(timeVec,yVec,
		outStart=outStart,outEnd=outEnd,intervalMinutes=intervalMinutes)
 
  	outTime = niceSeries$time
 	y = niceSeries$y
 	nPoints = length(y)
	imputed = rep(F,nPoints)
 	weightMatrix = NULL
 	predMatrix = NULL
	uncert = rep(0,nPoints)

	
	if (sum(is.na(y)) != 0) {
		# Fit time-of-week model, or time-of-week + predictive variable if provided, and 
		# use the predictions to fill in missing data.
	
		minuteOfWeek = 24*60*outTime$wday+60*outTime$hour + outTime$min
		intervalOfWeek = 1+floor(minuteOfWeek/intervalMinutes)
		ftow = factor(intervalOfWeek)
	
		if (!is.null(xTime) & !is.null(xVec)) {
			# A predictive variable has been provided, so use it in the model
			# First make sure the times in the sequence match with what we're using.
			
 			xNiceSeries = putTimeSeriesOnNiceIntervals(xTime,xVec,
 				outStart = outStart, outEnd = outEnd, intervalMinutes=intervalMinutes)
 			
 			# Use the predictive variable along with time-of-week to fill in missing
 			# values. 
 					
			dframe = data.frame(ftow,xNiceSeries)
 			imputed = which(is.na(y))			
			pred1 = fitModel(outTime, y, dframe)
			
 			weightMatrix = pred1$weightMatrix
 			predMatrix = pred1$predMatrix
 			uncert = pred1$StdErr
 			y[imputed] = pred1$y[imputed]
 	
 		}
		# If there are still NA, try again with just time of week model
		if (sum(is.na(y)) != 0) {
			imputed[is.na(y)] = T
			
			pred2 = fitModel(outTime,y,ftow)
			y[imputed] = pred2$y[imputed]
			uncert[imputed] = pred2$StdErr[imputed]
			
		}	

	}

	Out = NULL
	Out$time = outTime	
 	
	Out$yVec = y
	Out$imputed = imputed  # True or false, which points are imputed
	Out$weightMatrix = weightMatrix
	Out$predMatrix = predMatrix
	Out$StdErr = uncert
	return(Out)
	
}


#
#
makeTempMatrix = function(tempF,Tknots = c(40, 55, 65, 75, 90),checkBins=T, verbose=0) {
	# Input: vector of temperatures (degrees F)
	# Output: A matrix that breaks each temperature into bins, suitable for feeding
	# into a linear regression so as to get a piecewise-continuous model. For example,
	# with the default bins, a temperature of 58 will yield the following row of the 
	# matrix:
	# 40 15 10 3 0
	# this means "40 degrees up to 40F, plus 15 degrees to get to 55F, plus 10 degrees
	# to get to 65 F, plus 3 degrees to get to 68F, plus 0 degrees in the bin above 80F"
	if (verbose > 2) { print("starting makeTempMatrix") }
	
	Tknots = c(-1000,Tknots,1000)
	nKnots = length(Tknots)
	okKnots = rep(T,nKnots)
	
	if (checkBins) {
		numInBin = 0
		for (iKnot in 2:nKnots) {
			# how many temperatures are between Tknots[iKnot-1] and Tknots[iKnot]?
			numInBin = numInBin + sum((Tknots[iKnot-1] < tempF) & (tempF < Tknots[iKnot]))
			if (numInBin < 10) { 
				okKnots[iKnot] = F
				if (verbose > 4) {
					print(paste("Bin",iKnot,"doesn't have enough points. Temps",
					 Tknots[iKnot-1],Tknots[iKnot]))
				}	 
			} else {
				numInBin=0
			}
		}
	}
	Tknots = Tknots[okKnots]
	
	Tbinwidth = diff(Tknots) 
	
	nKnots = length(Tknots)

	nCol = nKnots-1
	outMat = matrix(0,nrow=length(tempF),ncol=nCol)

	outMat[,1] = ifelse(tempF < Tknots[2], tempF, Tknots[2])
	if (nCol > 1) {
		for (iKnot in 2:nCol) {
			outMat[,iKnot] =  ifelse(tempF > Tknots[iKnot], tempF-Tknots[iKnot], 0)
			outMat[,iKnot] = ifelse(outMat[,iKnot] > Tbinwidth[iKnot], 
				Tbinwidth[iKnot], outMat[,iKnot])
		}	
	}	
	Out = NULL
	Out$Tknots = Tknots
	Out$Tmat = outMat
	
	if (verbose > 2) { print("leaving makeTempMatrix") }

	return(Out)	
}

##
###########################

fillGaps = function(xvec,minGap=3) {
	# input xvec is a vector of T and F, representing whether time period is an
	# occupied mode or not, e.g. c(F,F,F,F,F,T,F,F,T,T,T,F,T,T,F,F,F,F,F)
	# If there are a few F sprinkled in among T, we want to replace them with T: they
	# are probably occupied periods that the algorithm didn't flag as such.
	# minGap specifies the minimum gap in NUMBER OF INTERVALS. E.g. minGap=3 could
	# mean 3 hours (if data are hourly) or 45 minutes (for 15-minute data)
	
	rl = rle(xvec)  # run lengths
	y = rep(rl$lengths, rl$lengths)
	y[xvec==T] = 0
	z = rep(F,length(xvec))
	z[y <= minGap] = T
	return(z)
	
}	



findOccUnocc = function(intervalOfWeek,loadVec,TempF,verbose=1) {
	if (verbose > 4) { print("starting findOccUnocc()") }
	# Figure out which times of week a building is in one of two modes
	#  (called 'occupied' or 'unoccupied'). This is NOT based on whether 
	# occupants are present: rather, in "occupied mode" the building is load is more
	# sensitive to outdoor air temperature than in "unoccupied mode."

	uTOW = sort(unique(intervalOfWeek))
	nTOW = length(uTOW)
	
	# Define 'occupied' and 'unoccupied' based on a regression
	# of load on outdoor temperature: times of week that the regression usually
	# underpredicts the load will be called 'occupied', the rest are 'unoccupied'
	# This is not foolproof but usually works well. 
	#	
	
	
	TempF50 = TempF-50
	TempF50[TempF > 50] = 0
	TempF62 = TempF-62
	TempF62[TempF < 62] = 0
	
	TempFbetween = TempF-50
	TempFbetween[TempF < 50] = 0
	TempFbetween[TempF > 62] = 0
	
	if (verbose > 4) {
		print("fitting temperature regression")
	}
	amod = lm(loadVec ~ TempF50 + TempFbetween + TempF62,na.action=na.exclude)
	
	okocc = rep(0,nTOW)
	for (itow in 1:nTOW) {
		okTOW = intervalOfWeek==uTOW[itow]
		# if the regression underpredicts the load more than 65% of the time
		# then assume it's an occupied period
		if ( sum(residuals(amod)[okTOW]>0,na.rm=T) > 0.65*sum(okTOW) ) {
			okocc[itow]=1
		}
	}
	firstMat = cbind(uTOW,okocc)
	
	# if there are a short (or not so short) intervals we tag as "unoccupied" but 
	# they're bounded on both
	# sides by "occupied" periods, re-label them as "occupied."
	outMat = firstMat
	outMat[,2] = fillGaps(outMat[,2],minGap=8)
	
	if (verbose > 4) { print("leaving findOccUnocc()") }
	return(outMat)
}



################
createDataStructure = function(tLoad,yLoad,tTemp=NULL,yTemp=NULL,
	tPredictors=NULL,xPredictors=NULL,xPredThresh=0.2, verbose=0) {
	# Create a data structure containing time, load, temperature, and predictive variables
	# The load data are king: put the temperature data and other predictors on the
	# same time intervals as the load data
	#
	# * Impute temperature and other predictive variables if necessary.
	# * Create temperature matrices to fit a piecewise-linear dependence on temperature
	# 	- fit separate temperature dependence for occupied and unoccupied modes, and
	#		startup period
	# *	Optionally, create separate matrices of other predictive variables to allow	
	#		different behavior when the variable is above vs below a specified	
	#		percentile (specified by xPredThresh). For instance, if a predictor
	#		variable is the number of active WiFi connections, you could allow a 
	#		different relationship between load and number of connections when the
	#		number is below the 20th percentile than when it is above the 20th percentile.
	#		
	if (verbose > 2) { print("starting createDataStructure") }
	timeCategories = NULL
	tempInfo = NULL
	
	tStart = tLoad[1]
	tEnd = tail(tLoad,1)
	nPoints = length(yLoad)
	intervalMinutes = round((as.numeric(tEnd) - as.numeric(tStart))/(60*nPoints))
	
	# load data should already be on nice time intervals, but just in case:
	LoadInfo = imputeTimeSeries(tLoad,yLoad,outStart=tStart,outEnd=tEnd,
			intervalMinutes=intervalMinutes)		
	tLoad = LoadInfo$time
	yLoad = LoadInfo$y
	nPoints = length(yLoad)

	minuteOfWeek = 24*60*tLoad$wday+60*tLoad$hour + tLoad$min
	intervalOfWeek = 1+floor(minuteOfWeek/intervalMinutes)
	ftow = factor(intervalOfWeek)
	

	if (sum(LoadInfo$imputed) > 0.05*length(LoadInfo$yVec)) {
		stop("Stopping: would have to impute more than 5% of load data.")
	}
	
	if (!is.null(yTemp)) {
		# Use imputeTimeSeries for each series of predictors, 
		#	in case there are missing data
		
		TempInfo = imputeTimeSeries(tTemp,yTemp,outStart=tStart,outEnd=tEnd,
			intervalMinutes=intervalMinutes)
			
		# Split times of the week into "unoccupied mode", "startup mode",
		# and "occupied mode." Modes are based on when the building is more or
		# less sensitive to outdoor air temperature, not on when the building is
		# actually occupied. (More sensitive to outdoor temperature presumably means
		# the building is heated or cooled within a tighter band). 
		timeCategories = findTimeCategories(tLoad,yLoad,
			TempInfo$yVec,intervalMinutes,verbose=verbose)
		
		tempMatrices = NULL
		Tknots = NULL
		for (icol in 1:ncol(timeCategories)) {
			tm =  makeTempMatrix(TempInfo$yVec[timeCategories[,icol]==1])
			Tknots[[icol]] = tm$Tknots
			TmatCatOnly = tm$Tmat
			# TmatCatOnly is the temperature matrix for just those times that are in 
			# the time category. But what we want is a matrix that has one row per
			# data point in the entire dataset, but is filled with zeroes except for 
			# those times. So build that now.
			TmatCat = matrix(0,nrow=nPoints,ncol = ncol(TmatCatOnly))
			TmatCat[timeCategories[,icol]==1,] = TmatCatOnly
			tempMatrices[[icol]] = TmatCat
		}

	}
	
	if (!is.null(xPredictors)) {
		xPredictors = as.matrix(xPredictors)
		predMat = matrix(NA,nrow=nPoints,ncol=ncol(xPredictors))
		pImputed = matrix(NA,nrow=nPoints,ncol=ncol(xPredictors))
	
		if (ncol(xPredictors) == 1) {
				pInfo = imputeTimeSeries(tPredictors, xPredictors[,1],outStart=tStart,
					outEnd = tEnd,intervalMinutes=intervalMinutes)
				predMat[,1] = pInfo$yVec
				pImputed[,1] = pInfo$imputed
			} else {
				# if two or more predictive variables are provided, impute 
				# missing values of the first 
				# one using the second, and then all of the others using the first one 
				# (including its imputed values). This makes sense if the first one 
				# is the "best" one and the second one is second-best.
				# Doing a joint prediction with all of them would be best, but is much 
				# more complicated, especially if they all have missing values at 
				# different places.
				pInfo = imputeTimeSeries(tPredictors, xPredictors[,1],outStart=tStart,
					outEnd = tEnd, tPredictors, xPredictors[,2])
				predMat[,1] = pInfo$yVec
				pImputed[,1] = pInfo$imputed	
				for (iCol in 2:nCol) {	
					pInfo2 = imputeTimeSeries(tPredictors, xPredictors[,iCol],outStart=tStart,
						outEnd = tEnd, xtime=pInfo$time, xVec=predMat[,1],
						intervalMinutes=intervalMinutes)
					predMat[,iCol] = pInfo2$yVec
					pImputed[,1] = pInfo2$imputed	
			}		
		}
	
		# In addition to providing predictive variables ("predictors")
		# in the form of a matrix, we provide two additional matrices: 
		# one that contains the predictive variables where they are below a given quantile
		# but zero elsewhere, and one that contains the predictive variables where they
		# exceed a given quantile but are zero elsewhere. If no quantile is provided,
		# we put the full matrix of predictive variables into both slots. 
		#
		predictorMatrices = NULL
		predictorMatrices[[1]] = predMat
		predictorMatrices[[2]] = predMat
		if (xPredThresh < 0 & verbose > 0) { print("warning: xPredThresh < 0") }
		if (xPredThresh > 1 & verbose > 0) { print("warning: xPredThresh > 1") }
		
		if (!is.null(xPredThresh) & xPredThresh >= 0 & xPredThresh <= 1) {	
			for (icol in 1:ncol(predMat)) {
				thresh = quantile(predMat[,icol],p=xPredThresh)
				predictorMatrices[[1]][predMat[,icol] > thresh,icol] = 0
				predictorMatrices[[2]][predMat[,icol] <= thresh,icol] = 0
			}
		}
	}
	Out = NULL
	
	Out$time = tLoad
	Out$timeCategories = timeCategories
	Out$load = yLoad
	Out$temp = TempInfo$yVec
	Out$Tknots = Tknots
	Out$tempMatrices = tempMatrices
	Out$tempImputed = TempInfo$imputed
	Out$predictors = predMat
	Out$predictorMatrices = predictorMatrices
	Out$pImputed = pImputed
	Out$intervalOfWeek = intervalOfWeek
	Out$intervalMinutes = intervalMinutes

	if (verbose > 2) { print("leaving createDataStructure") }
	
	return(Out)
		
}

###
####################
findTimeCategories = function(tLoad,load,temp=NULL,intervalMinutes,intervalOfWeek=NULL,
	startMinutes=120,verbose=0) {
	# Find periods of the week that the building is in "occupied mode" and "unoccupied mode" 
	# and split the occupied mode into "startup" and "rest of day"
	# Note that these modes do NOT depend on actual occupancy: they are based on when data
	# suggest the building is heated or air conditioned to a greater or lesser degree.
	if (verbose > 2) { print("starting findTimeCategories") }
	
	nPoints = length(load)
	if (is.null(temp)) {
		# if temperature data aren't provided, we can't determine different operating
		# modes, so just put everything into "occupied non-startup."
		okOccLater = rep(1,length(load))
		okUnocc = rep(0,length(load))
		okStartup = rep(0,length(load))
		timeCategoryMat = cbind(okUnocc,okStartup,okOccLater)
	} else {
	
		# if intervalOfWeek isn't provided, calculate it:
		minuteOfWeek = 24*60*tLoad$wday+60*tLoad$hour + tLoad$min
		intervalOfWeek = 1+floor(minuteOfWeek/intervalMinutes)
	
		occMat = findOccUnocc(intervalOfWeek,load,temp,
			verbose=1) 
		occIntervals = occMat[which(occMat[,2]==1),1] 
		okOcc = intervalOfWeek %in% occIntervals
	
		timeOfDay = tLoad$hour + tLoad$min/60 
		okAfter4 = timeOfDay > 4 # after 4 a.m. 	
	
		# Define "startup" as: any 'occupied' period within startMinutes of the start of the day,
		# where the start of the day is defined as the first roccupied period of the day 
		# after 4 a.m. 
				
		okStartup = rep(0,nPoints)
		for (iDay in 0:6) {
			# run through days of the week
			okDay = tLoad$wday == iDay
			
			if (sum(okOcc & okDay) > 1) {
				# At least some times on this day of the week, the building is in 
				# 'occupied' mode.
				
				# For all examples of this day of the week in the dataset, find the start time.
				ok =  okDay & okAfter4 & okOcc	
				startTimes = aggregate(timeOfDay[ok],by=list(tLoad$yday[ok]),min,na.rm=T)$x
			
				thisDayStartTime = quantile(startTimes,p=0.2)[1]
				okStartup[okDay & okOcc & (thisDayStartTime <= timeOfDay) & 
					(timeOfDay < (thisDayStartTime+4))] = 1
			} 
		}
		okUnocc = !okOcc
		okOccLater = okOcc & !okStartup
	
	}
	timeCategoryMat = cbind(okUnocc,okStartup,okOccLater)
	
	if (verbose > 2) { print("leaving findTimeCategories") }
		
	return(timeCategoryMat)

}

prepareDataFrame = function(dataStruct,useIntervalOfWeek=T,useTemp=T,useOther=T) {
	# Put together a single data frame, for use in fitting the model, based on
	# data from the data structure. 
	#
	# This can probably be done a lot simpler by using cbind to put pieces together,

	if (useIntervalOfWeek & useTemp & useOther) {
		predFrame = data.frame(as.factor(
			dataStruct$intervalOfWeek),
			dataStruct$tempMatrices[[1]],
			dataStruct$tempMatrices[[2]],
			dataStruct$tempMatrices[[3]],
			dataStruct$predictorMatrices[[1]],
			dataStruct$predictorMatrices[[2]])
		return(predFrame)
	}		
	if (useIntervalOfWeek & useTemp & !useOther) {
		predFrame = data.frame(as.factor(
			dataStruct$intervalOfWeek),
			dataStruct$tempMatrices[[1]],
			dataStruct$tempMatrices[[2]],
			dataStruct$tempMatrices[[3]])
		return(predFrame)
	}
	if (useIntervalOfWeek & !useTemp & useOther) {
		predFrame = data.frame(as.factor(
			dataStruct$intervalOfWeek),
			dataStruct$predictorMatrices[[1]],
			dataStruct$predictorMatrices[[2]])		
		return(predFrame)
	}	
	if (useIntervalOfWeek & !useTemp & !useOther) {
		predFrame = data.frame(as.factor(
			dataStruct$intervalOfWeek))
	}
}


####################

#
fitModel = function(timeVec, yVec, predFrame, timescaleDays = 14, verbose=0) {
	# Fit a linear model to predict yVec as a linear combination of predFrame.
	# Inputs:
	#  timeVec: one timestamp per data point (may be numeric, string in Y-m-d H:M format,
	#		or a POSIX time). This is used to make final predictions that adapt with time
	#		if the behavior of the system changes with time.
	#  yVec: the variable to be predicted. Numeric. May contain NA.
	#  predFrame: A data frame or vector of predictive variables. May contain "time-of-week"
	#		variables as a column of type "factor." 
	if (verbose > 2) { print("starting fitModel") }


	timeVec = getTime(timeVec)
	timeNum = as.numeric(timeVec)
		
	# calculate total length of dataset, in days
	totalIntervalLength = (tail(timeNum,1)-timeNum[1])/(24*3600) 
	nPoints = length(yVec)
	
	nFits = 1 + floor(totalIntervalLength/timescaleDays)
	individualLength = totalIntervalLength/nFits
	timestep = individualLength * 24*60*60 # timestep in seconds
	
	predMatrix = matrix(0,nrow=nPoints,ncol=nFits)
	weightMatrix = matrix(0,nrow=nPoints,ncol=nFits)
	SEmatrix = matrix(0,nrow=nPoints,ncol=nFits)
	
	for (i in 1:nFits) {
		centralTime = getTime(timeNum[1] + (i-1)*timestep)
		tDiff = as.numeric(difftime(timeVec,centralTime,units="days"))
		weightvec = 14^2/(14^2 + tDiff^2)
		amod = lm(yVec ~ .+0,data=predFrame, na.action=na.exclude,	
			weight = weightvec)
		SE <- sqrt( sum( residuals(amod)^2, na.rm=T ) / amod$df.residual )

		weightMatrix[,i] = weightvec
		predMatrix[,i] = predict(amod,predFrame)
		SEmatrix[,i] = SE

	}
	
	yPred = apply(predMatrix*weightMatrix,1,sum)/apply(weightMatrix,1,sum)
	StdErr = apply(SEmatrix*weightMatrix,1,sum)/apply(weightMatrix,1,sum) 

	
	Out = NULL
	Out$yPred = yPred
	Out$StdErr = StdErr
	Out$predMatrix = predMatrix
	Out$weightMatrix = weightMatrix
	Out$SEmatrix = SEmatrix
	return(Out)
	if (verbose > 2) { print("leaving fitModel") }
	
}


trimDat = function(start, timevec, yvec, end=NULL, nDays = NULL) {
	# given a time vector and an associated data vector, trim them both to 
	# a specified time interval. Start time must be given explicitly.
	# End time can be specified as a number of days since the start, or as an
	# end time (in any format understood by getTime).
	numStart = as.numeric(getTime(start))
	numEnd = 1e12
	ytime = getTime(timevec)
	if (
		!is.null(end)) { numEnd = as.numeric(getTime(end)) 
	} else {
		if (!is.null(nDays)) {
			numEnd = as.numeric(numStart) + 24*3600*nDays	
		} 
	}
	ok = numStart <= ytime & ytime <= numEnd
	Out = NULL
	Out$yvec = yvec[ok]
	Out$time = getTime(ytime[ok])
	return(Out)
	
}


GoodnessOfFit = function(time1, loadVec, time2, baselinePred, verbose=1) {
	fail=F	
	if (verbose > 1) { print("starting GoodnessOfFit()") }
	if (length(loadVec) != length(baselinePred)) {
		if (verbose > 0) { 
			print("Warning: GoodnessOfFit: vector length mismatch")
			fail = T 
		}
	}
	if (sum(abs(as.numeric(time1) - as.numeric(time2))) > 0) {
		if (verbose > 0) {
			print("Warning: GoodnessOfFit: timestamps do not match") 
			fail = T
		}
	}
	
	if (fail) { 
		# something's wrong, return NAs
		resid = rep(NA,length(time1)) 
	} else { 
		resid = loadVec-baselinePred
	}	
	iHour = time1$year*366*24+time1$yday*24+time1$hour
	ok_8AM_6PM = 7 < time1$hour & time1$hour < 19
	
	loadVecHour = aggregate(loadVec,by=list(iHour),mean,na.action=na.omit)[,2]
	baselinePredHour = aggregate(baselinePred,by=list(iHour),mean,na.action=na.omit)[,2]
	residHour = loadVecHour - baselinePredHour
		
	RMSE_Interval = sqrt(mean(resid^2,na.rm=T))
	RMSE_Interval_Daytime = sqrt(mean(resid[ok_8AM_6PM]^2,na.rm=T))
	
	RMSE_Hour = sqrt(mean(residHour^2,na.rm=T))

	MAPE_Interval = mean(abs(resid/loadVec),na.rm=T)*100
	MAPE_Interval_Daytime = mean(abs(resid[ok_8AM_6PM]/loadVec[ok_8AM_6PM]),
		na.rm=T)*100
	
	MAPE_Hour = mean(abs(residHour/loadVecHour),na.rm=T)*100	
	
	corr_Interval = cor(loadVec,baselinePred,use="complete.obs")
	corr_Interval_Daytime = cor(loadVec[ok_8AM_6PM],baselinePred[ok_8AM_6PM],use="complete.obs")
	corr_Hour = cor(loadVecHour,baselinePredHour,use="complete.obs")

	if(verbose > 1) { print("leaving GoodnessOfFit()") }
	Out = NULL
	Out$RMSE_Interval = RMSE_Interval
	Out$MAPE_Interval = MAPE_Interval
	Out$corr_Interval = corr_Interval
	Out$RMSE_Hour = RMSE_Hour
	Out$MAPE_Hour = MAPE_Hour
	Out$corr_Hour = corr_Hour
	Out$RMSE_Interval_Daytime = RMSE_Interval_Daytime
	Out$MAPE_Interval_Daytime = MAPE_Interval_Daytime
	Out$corr_Interval_Daytime = corr_Interval_Daytime
	return(Out)
}

#
# Here's the call to the main program in baseline.R; in order to use the same command line
# call that we use in baseline.r (so as to maintain backwards compatibility) we need to
# rewrite our main() so we can call it this way, 
# (and extend by adding additional optional variables).
# main(inLoadFile=inLoadFile,
#	timeStampFile=timeStampFile,
#	inTemperatureFile=inTemperatureFile,
#	inPredTemperatureFile=inPredTemperatureFile,
#	outBaselineFile=outBaselineFile,
#	outGoodnessOfFitFile=outGoodnessOfFitFile,
#	intervalMinutes=intervalMinutes,
#	timescaleDays=timescaleDays, 
#	fahrenheit = fahrenheit,
#	verbose=verbosity)



main = function(loadFile,timeStampFile=NULL,occFile=NULL,weatherDirectory=NULL,tempDat=NULL,xPredThresh=NULL,
	verbose=0) {
	
	loadDat = read.table(loadFile,
		header=T,sep=",",as.is=T)
	tLoad = getTime(loadDat[,1])
	yLoad = loadDat[,2]
	
	occDat = read.table(occFile, header=T,sep=",",as.is=T)
	tOcc = getTime(occDat[,1])
	yOcc = occDat[,2]
	
	if (is.null(tempDat)) {
		tempDat = combineWeatherData(weatherDirectory)
	}	
	tTemp = tempDat$results[,1]
	yTemp = tempDat$results[,2]
	
	dataStruct = createDataStructure(tLoad,yLoad,tTemp,yTemp,tOcc,yOcc,
		xPredThresh=xPredThresh,verbose=verbose)
	#preparedData = prepareLBNLmodel(dataStruct)
	# Need to call fitData here

	Out = NULL
	Out$dataStruct = dataStruct
	Out$tempDat = tempDat
	#Out$prepared = preparedData
	return(Out)
}

